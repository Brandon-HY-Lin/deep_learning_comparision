{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = './data'\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_data = FashionMNIST(root=path_data, download=True, train=True, transform=transform)\n",
    "test_data = FashionMNIST(root=path_data, download=True, train=False, transform=transform)\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "          'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n",
      "torch.Size([10, 1, 3, 3])\n",
      "torch.Size([10])\n",
      "torch.Size([20, 10, 3, 3])\n",
      "torch.Size([20])\n",
      "torch.Size([10, 500])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # in shape=(1, 28, 28), out shape=(10, 26, 26)  (zero-padding, i.e. valid)\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        # in shape=(10, 13, 13), out shape=(20, 11, 11)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3)\n",
    "        \n",
    "        # in shape=(20*5*5), out shape=(10)\n",
    "        self.fc1 = nn.Linear(20*5*5, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "net = CNN()\n",
    "print(net)\n",
    "for p in net.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Negative Log Likelihood Loss (NLL Loss)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Train process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs):\n",
    "    print_period = 1000\n",
    "    loss_over_time = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for index_batch, (inputs, labels) in enumerate(train_loader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "            y_hat = net.forward(inputs)\n",
    "            \n",
    "            loss = criterion(y_hat, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            \n",
    "            if index_batch % print_period == (print_period - 1):\n",
    "                avg_loss = running_loss / print_period\n",
    "                loss_over_time.append(avg_loss)\n",
    "                \n",
    "                print('Epoch:{}, Batch:{}, Avg loss:{}'.format(\n",
    "                    epoch, index_batch, avg_loss\n",
    "                ))\n",
    "                \n",
    "                running_loss = 0.0\n",
    "                \n",
    "    print('Finished Training')\n",
    "    return loss_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Batch:999, Avg loss:2.2889203345775604\n",
      "Epoch:1, Batch:999, Avg loss:2.178057375192642\n",
      "Epoch:2, Batch:999, Avg loss:1.7991369761228562\n",
      "Epoch:3, Batch:999, Avg loss:1.5904617938995362\n",
      "Epoch:4, Batch:999, Avg loss:1.528907211780548\n",
      "Epoch:5, Batch:999, Avg loss:1.5076966230273248\n",
      "Epoch:6, Batch:999, Avg loss:1.400166346013546\n",
      "Epoch:7, Batch:999, Avg loss:1.3373704303503036\n",
      "Epoch:8, Batch:999, Avg loss:1.3072202153801917\n",
      "Epoch:9, Batch:999, Avg loss:1.3075704311728478\n",
      "Epoch:10, Batch:999, Avg loss:1.2877609106302261\n",
      "Epoch:11, Batch:999, Avg loss:1.275410022199154\n",
      "Epoch:12, Batch:999, Avg loss:1.2631211723685265\n",
      "Epoch:13, Batch:999, Avg loss:1.252165415227413\n",
      "Epoch:14, Batch:999, Avg loss:1.2439380726218223\n",
      "Epoch:15, Batch:999, Avg loss:1.2386520525217057\n",
      "Epoch:16, Batch:999, Avg loss:1.2294009672999382\n",
      "Epoch:17, Batch:999, Avg loss:1.2256276106238366\n",
      "Epoch:18, Batch:999, Avg loss:1.2179107248187064\n",
      "Epoch:19, Batch:999, Avg loss:1.213337930560112\n",
      "Epoch:20, Batch:999, Avg loss:1.2062832839488984\n",
      "Epoch:21, Batch:999, Avg loss:1.2001839619874954\n",
      "Epoch:22, Batch:999, Avg loss:1.1936446929574012\n",
      "Epoch:23, Batch:999, Avg loss:1.1961326417922973\n",
      "Epoch:24, Batch:999, Avg loss:1.1904037762880326\n",
      "Epoch:25, Batch:999, Avg loss:1.1798435494601727\n",
      "Epoch:26, Batch:999, Avg loss:1.188620230257511\n",
      "Epoch:27, Batch:999, Avg loss:1.1819115815758705\n",
      "Epoch:28, Batch:999, Avg loss:1.1782289509773254\n",
      "Epoch:29, Batch:999, Avg loss:1.1709205426573754\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "training_loss = train(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Validation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:1.190068\n",
      "Test Accuracy of T-shirt/top: 88.70431893687707 (267.0/301.0)\n",
      "Test Accuracy of Trouser: 90.82278481012658 (287.0/316.0)\n",
      "Test Accuracy of Pullover: 0.0 (0.0/345.0)\n",
      "Test Accuracy of Dress: 93.67088607594937 (296.0/316.0)\n",
      "Test Accuracy of Coat: 0.0 (0.0/310.0)\n",
      "Test Accuracy of Sandal: 93.86503067484662 (306.0/326.0)\n",
      "Test Accuracy of Shirt: 0.0 (0.0/311.0)\n",
      "Test Accuracy of Sneaker: 94.01993355481727 (283.0/301.0)\n",
      "Test Accuracy of Bag: 93.64548494983278 (280.0/299.0)\n",
      "Test Accuracy of Ankle boot: 0.0 (0.0/305.0)\n",
      "Test Accuracy (Overall): 54.92012779552716 (1719.0/3130.0)\n"
     ]
    }
   ],
   "source": [
    "def valid():\n",
    "    test_loss = torch.zeros(1)\n",
    "    \n",
    "    class_correct = list(0. for _ in range(10))\n",
    "    class_total = list(0. for _ in range(10))\n",
    "    \n",
    "    \n",
    "    for batch_i, (inputs, labels) in enumerate(test_loader):\n",
    "        \n",
    "        outputs = net.forward(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # running average\n",
    "        test_loss = test_loss + ((torch.ones(1) / (batch_i + 1)) * (loss.data - test_loss))\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        correct = np.squeeze(predicted.eq(labels.data.view_as(predicted)))\n",
    "        \n",
    "        for i in range(10):\n",
    "            label = labels.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "            \n",
    "            \n",
    "    print('Test loss:{:.6f}'.format(test_loss.numpy()[0]))\n",
    "        \n",
    "        \n",
    "    for i in range(10):\n",
    "        if class_total[i] > 0:\n",
    "            print('Test Accuracy of {}: {} ({}/{})'.format(\n",
    "                classes[i], 100. * class_correct[i] / class_total[i],\n",
    "                np.sum(class_correct[i]), np.sum(class_total[i])\n",
    "            ))\n",
    "        else:\n",
    "            print('Test Accuracy of {}: N/A (No training examples)'.format(classes[i]))\n",
    "        \n",
    "        \n",
    "    print('Test Accuracy (Overall): {} ({:2.1f}/{:2.1f})'.format(\n",
    "        100. * np.sum(class_correct) / np.sum(class_total),\n",
    "        np.sum(class_correct), np.sum(class_total)\n",
    "    ))\n",
    "    \n",
    "    \n",
    "valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
